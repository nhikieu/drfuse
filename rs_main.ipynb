{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhikieu/Documents/GitHub/drfuse/drfuse_venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/var/folders/r1/ppflr8wn41l2jdfy7lw9p_n80000gn/T/ipykernel_8622/802642035.py:8: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from models import DrFuse_RS_Model, DrFuse_RS_Trainer\n",
    "import lightning as L\n",
    "import time\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.autonotebook import tqdm\n",
    "import skimage.io as io\n",
    "import earthpy.spatial as es\n",
    "import numpy as np\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/1720584936\n"
     ]
    }
   ],
   "source": [
    "now = str(int(time.time()))\n",
    "\n",
    "EXPERIMENT_CONFIG = dict(\n",
    "    # window data folder\n",
    "    # DATA_FOLDER = r'D:\\CarsSegmentationTroubleShoot\\data\\multimodal',\n",
    "    # mac data folder\n",
    "    DATA_FOLDER = r'/Users/nhikieu/Documents/PhD/multimodal',\n",
    "    num_epoch = 100, \n",
    "    img_size = 512, \n",
    "    num_classes = 6,\n",
    "    input_channels = 5,\n",
    "    batch_size = 4,\n",
    "    checkpoint_pth = os.path.join('checkpoints', now),\n",
    "    update_optim_size = 32\n",
    "    )\n",
    "DEVICE = 'mps'\n",
    "\n",
    "print(EXPERIMENT_CONFIG['checkpoint_pth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_class(mask_image):\n",
    "  class_map = {\n",
    "    (255,255,255): 0, \n",
    "    (0,0,255): 1, \n",
    "    (0,255,255): 2, \n",
    "    (0,255,0): 3, \n",
    "    (255,255,0): 4, \n",
    "    (255,0,0): 5\n",
    "  }\n",
    "\n",
    "  # Create a 3D numpy array that represents the RGB color of each pixel\n",
    "  rgb_data = mask_image.reshape(-1, 3)\n",
    "\n",
    "  # Create a 1D numpy array that represents the class label for each RGB color\n",
    "  class_labels = np.zeros(rgb_data.shape[0], dtype=np.uint8)\n",
    "  for rgb, class_label in class_map.items():\n",
    "      mask = np.all(rgb_data == np.array(rgb), axis=1)\n",
    "      class_labels[mask] = class_label\n",
    "\n",
    "  # Reshape the 1D class label array into a 2D class map\n",
    "  class_data = class_labels.reshape(mask_image.shape[:2])\n",
    "\n",
    "  return class_data\n",
    "\n",
    "\n",
    "class VaihingenDataset(Dataset):\n",
    "  def __init__(self, folder) -> None:\n",
    "    '''\n",
    "    folder: data path include both rgb img and gt\n",
    "    gt: 3 channels map with postfix '_gt'\n",
    "    '''\n",
    "    super().__init__()\n",
    "\n",
    "    self.imgs = []\n",
    "    self.gts = []\n",
    "\n",
    "    # get all filenames in the directory\n",
    "    filenames = os.listdir(os.path.join(folder, 'rgb'))\n",
    "    filenames = filenames[:1200]\n",
    "\n",
    "    for f in tqdm(filenames):\n",
    "      img = io.imread(os.path.join(folder, 'rgb', f)) / 255.0\n",
    "     \n",
    "      ndsm = io.imread(os.path.join(folder, 'ndsm', f.split('.png')[0] + '_ndsm.tif'))\n",
    "      ndsm = np.expand_dims(ndsm, axis=2)\n",
    "    \n",
    "      input_4C = np.dstack((img, ndsm))\n",
    "\n",
    "      input_4C = torch.tensor(input_4C).permute((2, 0, 1))\n",
    "      \n",
    "      gt_path = os.path.join(folder, 'gt', f.split('.png')[0] + '_gt.png')\n",
    "      gt = io.imread(gt_path)\n",
    "      gt = rgb_to_class(gt)\n",
    "      gt = torch.tensor(gt).unsqueeze(0)\n",
    "\n",
    "      self.imgs.append(input_4C)\n",
    "      self.gts.append(gt)\n",
    "    \n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.imgs)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    input_4C = self.imgs[index].float()\n",
    "    gt = self.gts[index]\n",
    "\n",
    "    # mask_array = [True, False]\n",
    "    mask_index = np.random.choice(2, 1, p=[0.5, 0.5])\n",
    "    mask = mask_index[0]\n",
    "\n",
    "    return input_4C, gt, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:41<00:00, 28.74it/s]\n",
      "100%|██████████| 120/120 [00:04<00:00, 28.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1200\n",
      "Val samples: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Note that we are using ground truth in the folder '1CGT'. They are not RGB anymore, but one channel.\n",
    "training_dataset = VaihingenDataset(os.path.join(EXPERIMENT_CONFIG['DATA_FOLDER'], 'train'))\n",
    "validate_dataset = VaihingenDataset(os.path.join(EXPERIMENT_CONFIG['DATA_FOLDER'], 'val'))\n",
    "\n",
    "#Note that we shuffle the data for the training set, but not for the validation set:\n",
    "train_loader = DataLoader(dataset=training_dataset, batch_size=EXPERIMENT_CONFIG['batch_size'], shuffle=True, pin_memory=True)\n",
    "validate_loader = DataLoader(dataset=validate_dataset, batch_size=EXPERIMENT_CONFIG['batch_size'], shuffle=True, pin_memory=True)\n",
    "\n",
    "print(f'Train samples: {len(training_dataset)}')\n",
    "print(f'Val samples: {len(validate_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/Users/nhikieu/Documents/GitHub/drfuse/drfuse_venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnhikieu\u001b[0m (\u001b[33mqut_nhi_phd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnhikieu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nhikieu/Documents/GitHub/drfuse/wandb/run-20240710_141623-22cii5s5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nhikieu/drfuse/runs/22cii5s5' target=\"_blank\">serene-salad-6</a></strong> to <a href='https://wandb.ai/nhikieu/drfuse' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nhikieu/drfuse' target=\"_blank\">https://wandb.ai/nhikieu/drfuse</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nhikieu/drfuse/runs/22cii5s5' target=\"_blank\">https://wandb.ai/nhikieu/drfuse/runs/22cii5s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/Users/nhikieu/Documents/GitHub/drfuse/drfuse_venv/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py:115: UserWarning: input's size at dim=0 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
      "  warnings.warn(\n",
      "Python(8880) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(8887) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(8894) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(8901) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(8908) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(8915) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(8922) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(8929) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(8943) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(8950) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(8957) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(8964) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "# ckpt_path = r\"D:\\mmformer\\checkpoints\\gan_distill\\1718106692\\1718160435_loss0.7109\"\n",
    "with wandb.init(project=\"drfuse\", entity=\"nhikieu\", config=EXPERIMENT_CONFIG):\n",
    "    config = wandb.config\n",
    "    model_trainer = DrFuse_RS_Trainer(config)\n",
    "    model_trainer(train_loader, validate_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhikieu/Documents/GitHub/drfuse/drfuse_venv/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py:115: UserWarning: input's size at dim=0 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 6, 512, 512]) torch.Size([6, 6, 512, 512]) torch.Size([6, 6, 512, 512]) torch.Size([6, 6, 512, 512]) torch.Size([6, 6, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "dummies = torch.rand(6, 4, 512, 512)\n",
    "masks = torch.FloatTensor([True, False, True, True, False, False])\n",
    "model = DrFuse_RS_Model()\n",
    "results = model(dummies, masks)\n",
    "print(results['pred_rgb'].shape, results['pred_ndsm'].shape, \n",
    "      results['pred_shared'].shape, results['pred_multimodal'].shape,\n",
    "      results['aux_preds'][0].shape)\n",
    "\n",
    "# Assuming model is an instance of a class derived from torch.nn.Module\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = torch.FloatTensor([True, False, True, False, True, True])\n",
    "pairs = pairs.unsqueeze(1)\n",
    "feat_dummy = torch.randn(6, 512)\n",
    "test = pairs*feat_dummy\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_4C, gt, mask) in enumerate(validate_loader):\n",
    "  print(input_4C.shape, gt.shape, mask.shape)\n",
    "  print(mask)\n",
    "  break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drfuse_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
